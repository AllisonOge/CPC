{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3f7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d1e6d",
   "metadata": {},
   "source": [
    "### **CPC model development**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f469fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPC(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 hidden_features: int,\n",
    "                 slice_length: int = 1024,\n",
    "                 history_steps: int = 8,\n",
    "                 drop_rate: float = 0.2,\n",
    "                 drop_path_rate: float = 0.7):\n",
    "        super(CPC, self).__init__()\n",
    "\n",
    "        # define some hyperparameters\n",
    "        self.slice_length = slice_length\n",
    "        self.history_steps = history_steps\n",
    "\n",
    "        # define an encoder\n",
    "        self.encoder = timm.create_model(\n",
    "            \"resnet18\",\n",
    "            in_chans=in_features,\n",
    "            num_classes=hidden_features,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "        )\n",
    "\n",
    "        # define the autoregressive model\n",
    "        self.autoregressor = nn.GRU(\n",
    "            input_size=hidden_features,\n",
    "            hidden_size=hidden_features,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x is of shape (B, Ca, C, T)\n",
    "\n",
    "        # some preprocessing: slice the input into chunks of length slice_length without overlap\n",
    "        x = x.unfold(3, self.slice_length,\n",
    "                     self.slice_length).permute(0, 3, 1, 2, 4)  # (B, num_chunks, Ca, C, slice_length)\n",
    "\n",
    "        # pass the input through the encoder\n",
    "        B, N, Ca, C, T = x.size()\n",
    "        x = self.encoder(x.contiguous().view(B*N, Ca, C, T))\n",
    "        x = x.view(B, N, -1)  # (B, num_chunks, D)\n",
    "\n",
    "        # pass the history_steps chunks through the autoregressive model\n",
    "        h0 = torch.zeros(1, x.size(0), x.size(-1)\n",
    "                         ).to(x.device)  # (num_layers, B, D)\n",
    "\n",
    "        c, h0 = self.autoregressor(x[:, :self.history_steps])  # (B, history_steps, D) # noqa\n",
    "\n",
    "        return c[:, -1], x[:, self.history_steps:], h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcfc0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(c_t, z_fut, temperature=1.0):\n",
    "    # c_t is of shape (B, D) and z_fut is of shape (B, K, D)\n",
    "    # normalize the vectors\n",
    "    c_t = F.normalize(c_t, p=2, dim=-1)\n",
    "    z_fut = F.normalize(z_fut, p=2, dim=-1)\n",
    "\n",
    "    # compute the cosine similarity\n",
    "    logits = torch.einsum(\"bd, bkd -> bk\", c_t, z_fut) / temperature  # (B, K)\n",
    "\n",
    "    true_labels = torch.zeros(logits.size(\n",
    "        0), device=logits.device).long()  # (B,)\n",
    "\n",
    "    # compute the loss\n",
    "    return F.cross_entropy(logits, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec321334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672823e4",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261654e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params={'lr': 0.00026324240451597926, 'weight_decay': 0.0006328245579438751, 'temperature': 0.8613165981723009, 'slice_length': 256, 'history_steps': 8, 'drop_rate': 0.014582702150573057, 'drop_path_rate': 0.3097614472574182}\n",
    "# params={'lr': 0.004579759039904434, 'weight_decay': 0.00012386582585723483, 'temperature': 0.0966689791227939, 'slice_length': 1536, 'history_steps': 24, 'drop_rate': 0.35419483772460636, 'drop_path_rate': 0.3174014557648441}\n",
    "config = {\n",
    "    \"in_features\": 4,\n",
    "    \"hidden_features\": 128,\n",
    "    \"slice_length\": 256,\n",
    "    \"history_steps\": 8,\n",
    "    \"drop_rate\": 0.014582702150573057,\n",
    "    \"drop_path_rate\": 0.3097614472574182,\n",
    "    \"temperature\": 0.8613165981723009,\n",
    "    \"batch_size\": 4,\n",
    "    \"experiment_name\": f\"cpc_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n",
    "    \"num_epochs\": 30,\n",
    "    \"learning_rate\": 0.00026324240451597926,\n",
    "    \"weight_decay\": 0.0006328245579438751,\n",
    "    \"dataset_path\": \"./oct10_outdoor_gain_experiments\",\n",
    "    \"checkpoint_path\": None,\n",
    "    \"comment\": \"CPC model training\",\n",
    "}\n",
    "\n",
    "# dump the config\n",
    "path = os.path.join(\"./experiments\", config[\"experiment_name\"])\n",
    "os.makedirs(path, exist_ok=True)\n",
    "with open(os.path.join(path, \"config.yaml\"), \"w\") as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c343509",
   "metadata": {},
   "outputs": [],
   "source": [
    "class R22_Dataset(DatasetFolder):\n",
    "    \"\"\"\n",
    "    Ensures every sample tensor ends up the same length (the minimum\n",
    "    length across your entire dataset), by trimming.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, load_fn, transform=None, **kwargs):\n",
    "        super().__init__(root, loader=load_fn, transform=transform, **kwargs)\n",
    "        # 1) scan every file once to find the minimum length\n",
    "        lengths = []\n",
    "        for path, _ in self.samples:\n",
    "            # load only the array header, not the entire payload\n",
    "            arr = np.load(path, mmap_mode='r', allow_pickle=False)\n",
    "            lengths.append(arr.shape[-1])\n",
    "        self.min_length = min(lengths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index][0]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        # 2) trim the sample to the minimum length\n",
    "        sample = sample[..., :self.min_length]\n",
    "        return sample\n",
    "\n",
    "\n",
    "def load_fn(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = np.load(f)\n",
    "        _ = np.load(f, allow_pickle=True).item()\n",
    "    data = np.stack((data.real, data.imag), axis=1)\n",
    "    # normalize the data\n",
    "    data = (data - np.mean(data, axis=(1, 2), keepdims=True)) / \\\n",
    "        (np.std(data, axis=(1, 2), keepdims=True) + 1e-8)\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "\n",
    "dataset = R22_Dataset(\n",
    "    root=config[\"dataset_path\"],\n",
    "    load_fn=load_fn,\n",
    "    transform=lambda x: torch.from_numpy(x),\n",
    "    extensions=[\".npy\"],\n",
    ")\n",
    "\n",
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410dac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "xb = next(iter(dataloader))\n",
    "print(xb.shape)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef824bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CPC(\n",
    "    in_features=config[\"in_features\"],\n",
    "    hidden_features=config[\"hidden_features\"],\n",
    "    slice_length=config[\"slice_length\"],\n",
    "    history_steps=config[\"history_steps\"],\n",
    "    drop_rate=config[\"drop_rate\"],\n",
    "    drop_path_rate=config[\"drop_path_rate\"],\n",
    ").to(device)\n",
    "c_t, z_fut, _ = model(xb.to(device))\n",
    "print(c_t.shape, z_fut.shape)\n",
    "loss = nt_xent_loss(c_t, z_fut)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    \"\"\"\n",
    "    A class to track the best value of a metric.\n",
    "\n",
    "    :param metric: The name of the metric to track. If 'loss' is in the metric name, the goal is to minimize it.\n",
    "    :type metric: str\n",
    "    :param mode: The mode of tracking. Can be 'auto', 'min', or 'max'. Default is 'auto'.\n",
    "    :type mode: str, optional\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, metric, mode='auto'):\n",
    "        self.metric = metric\n",
    "        self.mode = mode\n",
    "        self.mode_dict = {\n",
    "            'auto': np.less if 'loss' in metric else np.greater,\n",
    "            'min': np.less,\n",
    "            'max': np.greater\n",
    "        }\n",
    "        self.operator = self.mode_dict[mode]\n",
    "        self._best = np.inf if self.operator == np.less else -np.inf\n",
    "\n",
    "    @property\n",
    "    def best(self):\n",
    "        return self._best\n",
    "\n",
    "    @best.setter\n",
    "    def best(self, value):\n",
    "        self._best = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638cfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config[\"learning_rate\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim,\n",
    "    T_max=config[\"num_epochs\"],\n",
    "    eta_min=1e-6,\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler(device=device.type, enabled=True)\n",
    "writer = SummaryWriter(\n",
    "    log_dir=os.path.join(\"./experiments/\", config[\"experiment_name\"]),\n",
    ")\n",
    "tracker = Tracker(\"loss/epoch\", mode=\"min\")\n",
    "\n",
    "start_epoch = 0\n",
    "# resume training from a checkpoint if it exists\n",
    "checkpoint_path = config[\"checkpoint_path\"]\n",
    "if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optim.load_state_dict(checkpoint[\"opt_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"sch_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "step = 0\n",
    "with tqdm(range(start_epoch, config[\"num_epochs\"])) as master_bar:\n",
    "    for epoch in master_bar:\n",
    "        model.train()\n",
    "        avg_loss = 0.0\n",
    "        with tqdm(dataloader) as pbar:\n",
    "            for xb in pbar:\n",
    "                xb = xb.to(device)\n",
    "                optim.zero_grad()\n",
    "\n",
    "                with torch.amp.autocast(device_type=device.type,\n",
    "                                        enabled=True):\n",
    "                    c_t, z_fut, _ = model(xb)\n",
    "                    loss = nt_xent_loss(c_t, z_fut)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                # clip gradients\n",
    "                scaler.unscale_(optim)\n",
    "                norm = torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(), 1.0, norm_type=2\n",
    "                )\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "\n",
    "                avg_loss += loss.item()\n",
    "\n",
    "                pbar.set_postfix(\n",
    "                    {\"loss/step\": loss.item(), \"norm\": norm.item()})\n",
    "                writer.add_scalar(\"loss/step\", loss.item(), step)\n",
    "                writer.add_scalar(\"norm/step\", norm.item(), step)\n",
    "                step += 1\n",
    "\n",
    "        avg_loss /= len(dataloader)\n",
    "        writer.add_scalar(\"loss/epoch\", avg_loss, epoch)\n",
    "        master_bar.write(f\"Epoch {epoch}: loss = {avg_loss:.4f}\")\n",
    "        scheduler.step()\n",
    "        writer.add_scalar(\n",
    "            \"learning_rate/epoch\",\n",
    "            optim.param_groups[0][\"lr\"],\n",
    "            epoch,\n",
    "        )\n",
    "        writer.flush()\n",
    "        if tracker.operator(avg_loss, tracker.best):\n",
    "            tracker.best = avg_loss\n",
    "            # Save the model checkpoint\n",
    "            checkpoint_path = os.path.join(\n",
    "                \"./experiments\", f\"{config['experiment_name']}/weights.pth\"\n",
    "            )\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Model saved to {checkpoint_path}\")\n",
    "        # save the latest checkpoint\n",
    "        checkpoint_path = os.path.join(\n",
    "            \"./experiments\", f\"{config['experiment_name']}/last_checkpoint.pt\")\n",
    "        torch.save({\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"opt_state_dict\": optim.state_dict(),\n",
    "            \"sch_state_dict\": scheduler.state_dict(),\n",
    "            \"epoch\": epoch}, checkpoint_path)\n",
    "        print(\n",
    "            f\"Latest checkpoint saved to {checkpoint_path} at epoch {epoch}\"\n",
    "        )\n",
    "\n",
    "writer.close()\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a0886",
   "metadata": {},
   "source": [
    "##### **Notes**\n",
    "\n",
    "- training has very dramatic gradient that dances around and loss is very noisy\n",
    "- use of gradient clipping and data normalization per sample (try whole batch normalization too) reduced the noisy loss but more improvements can be done\n",
    "- TODO: introduce the silhoutte score to determining if the clustering is improving during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75ad57",
   "metadata": {},
   "source": [
    "### **Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed74912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "# plot the TSNE and UMAP of the features\n",
    "# plot pseudo-labels using KMeans and compare with the ground truth\n",
    "encoder_model = timm.create_model(\n",
    "    \"resnet18\",\n",
    "    in_chans=config[\"in_features\"],\n",
    "    num_classes=config[\"hidden_features\"],\n",
    "    drop_rate=config[\"drop_rate\"],\n",
    "    drop_path_rate=config[\"drop_path_rate\"],\n",
    ").to(device)\n",
    "\n",
    "weights = torch.load(\n",
    "    \"./experiments/cpc_2025-05-05_01-16-11/weights.pth\", weights_only=True, map_location=device\n",
    ")\n",
    "weights = {k.replace(\"encoder.\", \"\"): v for k, v in weights.items()}\n",
    "msg = encoder_model.load_state_dict(\n",
    "    weights, strict=False)\n",
    "\n",
    "assert len(msg.missing_keys) == 0, f\"Missing keys: {msg.missing_keys}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
